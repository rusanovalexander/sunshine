(virtual-env) inghero@dsbox-gv20fi:~/data/irwbds/llm/parc/notebooks/PF_Case/pipline_pf_5/sunshine-master$ python -m src.main   --stage all   --ocr_method easyocr   --company "Autopista Terrassa_36033432" --skip_preprocess 

    ╔═══════════════════════════════════════════════════════════════╗
    ║     PROJECT SUNSHINE - Document Extraction Pipeline v2        ║
    ║     Multi-Pass Evidence-Based Extraction System               ║
    ╠═══════════════════════════════════════════════════════════════╣
    ║  Stage 1: Document Preprocessing                              ║
    ║  Stage 2: Multi-Pass Field Group Extraction                   ║
    ║  Stage 3: Deep Field Extraction (Fallback)                    ║
    ║  Stage 4: Verification & Consolidation                        ║
    ╚═══════════════════════════════════════════════════════════════╝
    
12:12:23 - Pipeline - INFO - Checking environment...
12:12:23 - Pipeline - INFO -   GPU: NVIDIA A100-PCIE-40GB MIG 4g.20gb (21.1 GB)
12:12:23 - Pipeline - INFO -   GPU Memory: 21.1GB free / 21.1GB total
12:12:25 - Pipeline - INFO -   All required packages available
12:12:25 - Pipeline - INFO - Checking paths...
12:12:25 - Pipeline - INFO -   LLM model: OK
12:12:25 - Pipeline - INFO -   VLM model: OK
12:12:25 - Pipeline - INFO -   Source data: OK
12:12:25 - Pipeline - INFO - Skipping preprocessing (--skip_preprocess)
12:12:25 - Pipeline - INFO - 
============================================================
12:12:25 - Pipeline - INFO - STAGE 2-4: MULTI-PASS EXTRACTION (consolidated per company)
12:12:25 - Pipeline - INFO - ============================================================
12:13:12 - Pipeline - INFO - Retriever type: embedding
12:13:12 - Pipeline - INFO - Loading LLM model...
12:13:12 - Pipeline - INFO - Loading model: /home/inghero/data/irwbds/llm/parc/qwen3_14B_bnb4
12:13:12 - Pipeline - INFO - Before model load: GPU Memory: 0.00GB allocated, 0.00GB reserved, 21.07GB free (0.0% used)
12:13:12 - Pipeline - INFO -   Pre-quantized model detected (bnb4), using optimized loader
12:13:14 - Pipeline - INFO - Loading LLM from /home/inghero/data/irwbds/llm/parc/qwen3_14B_bnb4
12:13:14 - Pipeline - INFO -   Detected quantization: bnb4
12:13:14 - Pipeline - INFO -   Config: Saved BnB 4-bit (pre-quantized), sdpa attn, no max_memory cap
Loading weights: 100%|█████████████████████████████████████████████████████████████████████████████████████████████| 443/443 [01:57<00:00,  3.79it/s, Materializing param=model.norm.weight]
12:18:23 - Pipeline - INFO -   ✓ Chat template available
12:18:23 - Pipeline - INFO - After LLM load: GPU Memory: 9.93GB allocated, 9.95GB reserved, 11.12GB free (47.2% used)
12:18:23 - Pipeline - INFO - Model loaded successfully
12:18:23 - Pipeline - INFO - After model load: GPU Memory: 9.93GB allocated, 9.95GB reserved, 11.12GB free (47.2% used)
12:18:23 - Pipeline - INFO - Loading embedding model from /home/inghero/data/irwbds/llm/parc/Qwen3-Embedding-0.6B...
12:18:23 - Pipeline - INFO - Loading embedding model from /home/inghero/data/irwbds/llm/parc/Qwen3-Embedding-0.6B
`torch_dtype` is deprecated! Use `dtype` instead!
Loading weights: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████| 310/310 [00:11<00:00, 26.28it/s, Materializing param=norm.weight]
12:18:43 - Pipeline - INFO -   Embedding model loaded on cuda
12:18:43 - Pipeline - INFO - Processing 1 companies (1 files total)
12:18:43 - Pipeline - INFO - 
════════════════════════════════════════════════════════════
12:18:43 - Pipeline - INFO - Company 1/1: Autopista Terrassa_36033432 (1 files)
12:18:43 - Pipeline - INFO - ════════════════════════════════════════════════════════════
12:18:43 - Pipeline - INFO -   Step 1: Consolidating all files...
12:18:43 - Pipeline - INFO - Consolidating 1 files for Autopista Terrassa_36033432
Token indices sequence length is longer than the specified maximum sequence length for this model (411190 > 131072). Running this sequence through the model will result in indexing errors
12:18:45 - Pipeline - INFO -   Combined document: 1,279,131 chars, ~411,190 tokens
12:18:45 - Pipeline - INFO -   Source files: 1
12:18:46 - Pipeline - INFO -   Creating chunks: 411190 tokens, size=2000, overlap=400
12:19:08 - Pipeline - INFO -   Created 257 chunks covering entire document
12:19:08 - Pipeline - INFO -   ✓ Complete coverage verified: 100.00%
12:19:08 - Pipeline - INFO -   Consolidated: 411,190 tokens, 257 chunks from 1 files
12:19:09 - Pipeline - INFO -   Saved consolidated document to extraction_outputs_v3/Autopista Terrassa_36033432
12:19:09 - Pipeline - INFO -   Document language detected: es
12:19:09 - Pipeline - INFO -   Encoding 257 chunks with embedding model...
12:19:14 - Pipeline - INFO -   Indexed 257 chunks → embeddings shape torch.Size([257, 1024])
12:19:14 - Pipeline - INFO -   Embedding model offloaded to CPU (GPU freed for LLM)
12:19:14 - Pipeline - INFO -   Step 2: Detecting facilities...
12:20:13 - Pipeline - INFO -       Facility detection: trimming from 29171 to 5000 tokens
12:20:13 - Pipeline - INFO -   LLM input: 5485 tokens, max_new_tokens=2048
The following generation flags are not valid and may be ignored: ['top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
12:20:20 - Pipeline - INFO - Detected 0 facilities
12:20:20 - Pipeline - INFO -   Found 0 facilities
12:20:20 - Pipeline - WARNING -   ✗ No data extracted for Autopista Terrassa_36033432
12:20:20 - Pipeline - WARNING - No data extracted
12:20:20 - Pipeline - ERROR - Extraction failed
(virtual-env) inghero@dsbox-gv20fi:~/data/irwbds/llm/parc/notebooks/PF_Case/pipline_pf_5/sunshine-master$ 
