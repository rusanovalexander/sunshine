python -m src.main \
  --stage all \
  --ocr_method easyocr \
  --retriever embedding \
  --company "YourCompanyName" \
  --flash_attention


python -c "import torch; print(torch.__version__); print(torch.version.cuda)"

16:47:05 - Pipeline - INFO -   Config: 4-bit NF4, double quant, sdpa, max 16.0GB
`torch_dtype` is deprecated! Use `dtype` instead!
Loading weights:  73%|██████████████████████████████████████████▎               | 323/443 [07:29<01:35,  1.26it/s, Materializing param=model.layers.29.mlp.down_proj.weight]


17:16:39 - Pipeline - INFO - STAGE 2-4: MULTI-PASS EXTRACTION (consolidated per company)
17:16:39 - Pipeline - INFO - ============================================================
17:16:40 - Pipeline - INFO - Retriever type: embedding
17:16:40 - Pipeline - INFO - Loading LLM model...
17:16:40 - Pipeline - INFO - Loading model: /home/inghero/data/irwbds/llm/parc/qwen3_14B
17:16:40 - Pipeline - INFO - Before model load: GPU Memory: 0.01GB allocated, 0.02GB reserved, 21.05GB free (0.1% used)
17:16:41 - Pipeline - INFO - Loading LLM from /home/inghero/data/irwbds/llm/parc/qwen3_14B
17:16:41 - Pipeline - INFO -   Config: 4-bit NF4, double quant, sdpa, max 16.0GB
`torch_dtype` is deprecated! Use `dtype` instead!





============================================================
17:56:50 - Pipeline - INFO - STAGE 2-4: MULTI-PASS EXTRACTION (consolidated per company)
17:56:50 - Pipeline - INFO - ============================================================
17:56:51 - Pipeline - INFO - Retriever type: embedding
17:56:51 - Pipeline - INFO - Loading LLM model...
17:56:51 - Pipeline - INFO - Loading model: /home/inghero/data/irwbds/llm/parc/qwen3_14B
17:56:51 - Pipeline - INFO - Before model load: GPU Memory: 0.01GB allocated, 0.02GB reserved, 21.05GB free (0.1% used)
17:56:53 - Pipeline - INFO - Loading LLM from /home/inghero/data/irwbds/llm/parc/qwen3_14B
17:56:53 - Pipeline - INFO -   Detected quantization: none
17:56:53 - Pipeline - INFO -   Config: 4-bit NF4 (BitsAndBytes), sdpa, max 16.0GB
`torch_dtype` is deprecated! Use `dtype` instead!

(virtual-env) inghero@dsbox-gv20fi:~/data/irwbds/llm/parc/notebooks/PF_Case/pipline_pf_4/sunshine-master$ python -m src.main   --stage all   --ocr_method easyocr   --retriever embedding   --company "ABP Acquisitions UK Limited_39306327"

    ╔═══════════════════════════════════════════════════════════════╗
    ║     PROJECT SUNSHINE - Document Extraction Pipeline v2        ║
    ║     Multi-Pass Evidence-Based Extraction System               ║
    ╠═══════════════════════════════════════════════════════════════╣
    ║  Stage 1: Document Preprocessing                              ║
    ║  Stage 2: Multi-Pass Field Group Extraction                   ║
    ║  Stage 3: Deep Field Extraction (Fallback)                    ║
    ║  Stage 4: Verification & Consolidation                        ║
    ╚═══════════════════════════════════════════════════════════════╝
    
17:36:00 - Pipeline - INFO - Checking environment...
17:36:00 - Pipeline - INFO -   GPU: NVIDIA A100-PCIE-40GB MIG 4g.20gb (21.1 GB)
17:36:00 - Pipeline - INFO -   GPU Memory: 21.1GB free / 21.1GB total
17:36:02 - Pipeline - INFO -   All required packages available
17:36:02 - Pipeline - INFO - Checking paths...
17:36:02 - Pipeline - INFO -   LLM model: OK
17:36:02 - Pipeline - INFO -   VLM model: OK
17:36:02 - Pipeline - INFO -   Source data: OK
17:36:02 - Pipeline - INFO - 
============================================================
17:36:02 - Pipeline - INFO - STAGE 1: DOCUMENT PREPROCESSING
17:36:02 - Pipeline - INFO - ============================================================
17:36:34 - Pipeline - INFO - === Company: ABP Acquisitions UK Limited_39306327 ===
17:36:35 - Pipeline - INFO - Processing: Transfer Cert - fully executed CS.pdf
17:36:55 - Pipeline - INFO - Processing: Cook_-_Fully_executed_SFA.pdf
17:56:31 - Pipeline - INFO - Processing: Transfer certificate - fully executed JPM.pdf
17:56:46 - Pipeline - INFO - Preprocessing complete. 3 files in manifest.
17:56:46 - Pipeline - INFO - Unloading VLM to free GPU memory...
17:56:50 - Pipeline - INFO - After VLM unload: GPU Memory: 0.01GB allocated, 0.02GB reserved, 21.05GB free (0.1% used)
17:56:50 - Pipeline - INFO - 
============================================================
17:56:50 - Pipeline - INFO - STAGE 2-4: MULTI-PASS EXTRACTION (consolidated per company)
17:56:50 - Pipeline - INFO - ============================================================
17:56:51 - Pipeline - INFO - Retriever type: embedding
17:56:51 - Pipeline - INFO - Loading LLM model...
17:56:51 - Pipeline - INFO - Loading model: /home/inghero/data/irwbds/llm/parc/qwen3_14B
17:56:51 - Pipeline - INFO - Before model load: GPU Memory: 0.01GB allocated, 0.02GB reserved, 21.05GB free (0.1% used)
17:56:53 - Pipeline - INFO - Loading LLM from /home/inghero/data/irwbds/llm/parc/qwen3_14B
17:56:53 - Pipeline - INFO -   Detected quantization: none
17:56:53 - Pipeline - INFO -   Config: 4-bit NF4 (BitsAndBytes), sdpa, max 16.0GB
`torch_dtype` is deprecated! Use `dtype` instead!
Loading weights: 100%|██████████████████████████████████████████████████████████████████████████████████████| 443/443 [08:36<00:00,  1.17s/it, Materializing param=model.norm.weight]
18:10:04 - Pipeline - INFO - After LLM load: GPU Memory: 9.97GB allocated, 12.12GB reserved, 8.95GB free (57.5% used)
18:10:04 - Pipeline - INFO - Model loaded successfully
18:10:04 - Pipeline - INFO - After model load: GPU Memory: 9.97GB allocated, 12.12GB reserved, 8.95GB free (57.5% used)
18:10:04 - Pipeline - INFO - Loading embedding model from /home/inghero/data/irwbds/llm/parc/Qwen3-Embedding-0.6B...
18:10:04 - Pipeline - INFO - Loading embedding model from /home/inghero/data/irwbds/llm/parc/Qwen3-Embedding-0.6B
Loading weights: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 310/310 [00:12<00:00, 25.39it/s, Materializing param=norm.weight]
18:10:27 - Pipeline - INFO -   Embedding model loaded on cuda
18:10:27 - Pipeline - INFO - Processing 1 companies (3 files total)
18:10:28 - Pipeline - INFO - 
════════════════════════════════════════════════════════════
18:10:28 - Pipeline - INFO - Company 1/1: ABP Acquisitions UK Limited_39306327 (3 files)
18:10:28 - Pipeline - INFO - ════════════════════════════════════════════════════════════
18:10:28 - Pipeline - INFO -   Step 1: Consolidating all files...
18:10:28 - Pipeline - INFO - Consolidating 3 files for ABP Acquisitions UK Limited_39306327
18:10:28 - Pipeline - INFO -   Combined document: 304,718 chars, ~75,754 tokens
18:10:28 - Pipeline - INFO -   Source files: 3
18:10:29 - Pipeline - INFO -   Creating chunks: 75754 tokens, size=3000, overlap=500
18:10:29 - Pipeline - INFO -   Created 31 chunks covering entire document
18:10:29 - Pipeline - INFO -   ✓ Complete coverage verified: 100.00%
18:10:29 - Pipeline - INFO -   Consolidated: 75,754 tokens, 31 chunks from 3 files
18:10:30 - Pipeline - INFO -   Saved consolidated document to extraction_outputs_v2/ABP Acquisitions UK Limited_39306327
18:10:30 - Pipeline - INFO -   Encoding 31 chunks with embedding model...
18:10:31 - Pipeline - INFO -   Indexed 31 chunks → embeddings shape torch.Size([31, 1024])
18:10:31 - Pipeline - INFO -   Step 2: Detecting facilities...
18:11:02 - Pipeline - INFO - Detected 3 facilities
18:11:02 - Pipeline - INFO -   Found 3 facilities
18:11:02 - Pipeline - INFO -   Step 3.1: Extracting for Term Loan C (Term Loan)
18:11:02 - Pipeline - INFO -     Extracting: Basic Facility Information
18:11:07 - Pipeline - ERROR - LLM generation error: NVML_SUCCESS == r INTERNAL ASSERT FAILED at "/pytorch/c10/cuda/CUDACachingAllocator.cpp":1154, please report a bug to PyTorch. 
18:11:07 - Pipeline - WARNING - Failed to parse JSON from response
18:11:09 - Pipeline - WARNING - Low GPU memory (0.85GB free), reducing max_tokens
18:11:21 - Pipeline - ERROR - LLM generation error: NVML_SUCCESS == r INTERNAL ASSERT FAILED at "/pytorch/c10/cuda/CUDACachingAllocator.cpp":1154, please report a bug to PyTorch. 
18:11:21 - Pipeline - WARNING - Failed to parse JSON from response
18:11:21 - Pipeline - INFO -     Extracting: Sponsor and Ownership
18:11:26 - Pipeline - ERROR - LLM generation error: NVML_SUCCESS == r INTERNAL ASSERT FAILED at "/pytorch/c10/cuda/CUDACachingAllocator.cpp":1154, please report a bug to PyTorch. 
18:11:26 - Pipeline - WARNING - Failed to parse JSON from response
18:11:28 - Pipeline - WARNING - Low GPU memory (0.85GB free), reducing max_tokens
18:11:39 - Pipeline - ERROR - LLM generation error: NVML_SUCCESS == r INTERNAL ASSERT FAILED at "/pytorch/c10/cuda/CUDACachingAllocator.cpp":1154, please report a bug to PyTorch. 
18:11:39 - Pipeline - WARNING - Failed to parse JSON from response
18:11:39 - Pipeline - WARNING - Low GPU memory (0.66GB free), reducing max_tokens
18:11:47 - Pipeline - ERROR - LLM generation error: NVML_SUCCESS == r INTERNAL ASSERT FAILED at "/pytorch/c10/cuda/CUDACachingAllocator.cpp":1154, please report a bug to PyTorch. 
18:11:47 - Pipeline - WARNING - Failed to parse JSON from response
18:11:48 - Pipeline - INFO -     Extracting: Project Details
18:11:54 - Pipeline - ERROR - LLM generation error: NVML_SUCCESS == r INTERNAL ASSERT FAILED at "/pytorch/c10/cuda/CUDACachingAllocator.cpp":1154, please report a bug to PyTorch. 
18:11:54 - Pipeline - WARNING - Failed to parse JSON from response
18:11:56 - Pipeline - WARNING - Low GPU memory (0.85GB free), reducing max_tokens
18:12:04 - Pipeline - ERROR - LLM generation error: NVML_SUCCESS == r INTERNAL ASSERT FAILED at "/pytorch/c10/cuda/CUDACachingAllocator.cpp":1154, please report a bug to PyTorch. 
18:12:04 - Pipeline - WARNING - Failed to parse JSON from response
18:12:04 - Pipeline - INFO -     Extracting: Construction and Guarantees
18:12:10 - Pipeline - ERROR - LLM generation error: NVML_SUCCESS == r INTERNAL ASSERT FAILED at "/pytorch/c10/cuda/CUDACachingAllocator.cpp":1154, please report a bug to PyTorch. 
18:12:10 - Pipeline - WARNING - Failed to parse JSON from response
18:12:12 - Pipeline - WARNING - Low GPU memory (0.85GB free), reducing max_tokens
18:12:21 - Pipeline - ERROR - LLM generation error: NVML_SUCCESS == r INTERNAL ASSERT FAILED at "/pytorch/c10/cuda/CUDACachingAllocator.cpp":1154, please report a bug to PyTorch. 
18:12:21 - Pipeline - WARNING - Failed to parse JSON from response
18:12:22 - Pipeline - INFO -     Extracting: Revenue Mitigating Factors
18:12:27 - Pipeline - ERROR - LLM generation error: NVML_SUCCESS == r INTERNAL ASSERT FAILED at "/pytorch/c10/cuda/CUDACachingAllocator.cpp":1154, please report a bug to PyTorch. 
18:12:27 - Pipeline - WARNING - Failed to parse JSON from response
18:12:29 - Pipeline - INFO -     Extracting: Financial Covenants
18:12:34 - Pipeline - ERROR - LLM generation error: NVML_SUCCESS == r INTERNAL ASSERT FAILED at "/pytorch/c10/cuda/CUDACachingAllocator.cpp":1154, please report a bug to PyTorch. 
18:12:34 - Pipeline - WARNING - Failed to parse JSON from response
18:12:36 - Pipeline - INFO -     Extracting: Syndication and ING Participation



def initialize_model(model_path=MODEL_PATH):
    logger.info(f"Initializing model: {model_path}")
    try:
        quant_config = BitsAndBytesConfig(load_in_4bit=True, bnb_4bit_compute_dtype=torch.float16)
        model = AutoModelForCausalLM.from_pretrained(model_path, quantization_config=quant_config, device_map="auto", trust_remote_code=True, attn_implementation="sdpa")
        tokenizer = AutoTokenizer.from_pretrained(model_path, trust_remote_code=True, padding_side='left')
        if tokenizer.pad_token is None: tokenizer.pad_token = tokenizer.eos_token
        logger.info("Model initialized successfully.")
        return model, tokenizer
    except Exception as e:
        logger.critical(f"FATAL: Model initialization failed: {e}", exc_info=True)
        return None, None
